project_name: "vae-project"
seed: 42

data:
  dataset_name: "celeba"  # Options: celeba, cifar10, fashion_mnist
  data_dir: "./data"
  batch_size: 64
  num_workers: 4
  image_size: 64          # 64 for CelebA, 32 for CIFAR10, 28/32 for FashionMNIST
model:
  latent_dim: 128
  base_channels: 32       # Starting number of channels in Encoder
  beta: 1.0               # KL-divergence weight (Beta-VAE)
  input_channels: 3       # 3 for RGB, 1 for Grayscale

trainer:
  max_epochs: 50
  learning_rate: 0.0005
  accelerator: "gpu"
  devices: 1
  check_val_every_n_epoch: 1
  log_every_n_steps: 10